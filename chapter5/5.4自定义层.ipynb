{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3240b4",
   "metadata": {},
   "source": [
    "不带参数的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde39d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torch import nn \n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"实现前向传播功能\"\"\"\n",
    "        return X-X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1121414b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf26f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813bfa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7070b5",
   "metadata": {},
   "source": [
    "带参数的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d905979",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units, ))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data \n",
    "        return F.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ce1bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9106,  0.1664, -0.0883],\n",
       "        [-0.1092,  0.0313, -1.0162],\n",
       "        [-0.3709,  1.3383,  1.4982],\n",
       "        [ 0.3242, -1.8513,  0.4223],\n",
       "        [ 0.9668,  1.1432, -0.5760]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = MyLinear(5, 3)   # 要求输入为5， 输出为3\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c7fb916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5194, 0.0000, 0.2807],\n",
       "        [1.3310, 0.0000, 0.0095]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(torch.rand(2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c107bae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3750],\n",
       "        [5.8235]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889435b",
   "metadata": {},
   "source": [
    "练习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6319d007",
   "metadata": {},
   "source": [
    "设计一个接受输入并计算张量降维的层, 它返回yk = sum(wijk * xi * xj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df74d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class downLayer(nn.Module):\n",
    "    \"\"\" \n",
    "    设计一个接受输入并计算张量降维的层, 它返回yk = sum(wijk * xi * xj)\n",
    "    这里只设置了接受单个样本\n",
    "    \"\"\"\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, in_units, units))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        返回yk = sum(wijk * xi * xj)\n",
    "\n",
    "        Parameter\n",
    "        ----------\n",
    "            X : 输入数据，(in_units, )\n",
    "        \"\"\"\n",
    "        X = X.unsqueeze(1) # unqueeze在指定位置增添一个维度, 即在第一维插入一个维度 (in_units, 1)\n",
    "        X_outer = torch.mm(X, X.t())  # (in_units, in_units)\n",
    "        y = torch.einsum('ij,jkl->kl', X_outer, self.weight)\n",
    "        # einsum 爱因斯坦求和约定\n",
    "        # 对输入中重复出现的标签j执行矩阵乘法\n",
    "        # 在输出中重复出现的标签k,l表示保留该维度\n",
    "        # 在输出中未重复出现(只在输入中出现)的标签i表示对该维度求和\n",
    "        # X_outer (i, j)   self.weight(j, k, l)\n",
    "        # 对X_outer的每个元素X[i,j]和self.weight的切片w[j,:,：]执行元素级乘法，得到temp[i, k, l]\n",
    "        # 对i维度求和，最终输出y[k,l]\n",
    "        \n",
    "        return y.squeeze() # squeeze 移除所有维度大小为1的维度，使张量的维度数减少\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66deca44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2253,  4.1714],\n",
       "        [ 4.3161, -0.4322],\n",
       "        [-1.2593,  0.4844],\n",
       "        [-0.9717, -1.1399],\n",
       "        [ 0.4264, -2.5725]], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1 = downLayer(5, 2)\n",
    "layer1(torch.randn(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f00e96",
   "metadata": {},
   "source": [
    "设计一个返回输入数据的傅里叶系数前半部分的层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4757f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierCoefficientLayer(nn.Module):\n",
    "    \"\"\" \n",
    "    返回输入数据的傅里叶系数前半部分的自定义层\n",
    "    支持1D、2D、3D的信号, 自动处理批量维度和通道维度\n",
    "    \"\"\"\n",
    "    def __init__(self, signal_dim=1):\n",
    "        \"\"\" \n",
    "        初始化傅里叶系数层\n",
    "\n",
    "        Parameter\n",
    "        ----------\n",
    "            signal_dim : 信号维度, 1表示1D信号, 2表示2D信号, 3表示3D信号\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.signal_dim = signal_dim\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\" \n",
    "        前向传播计算 \n",
    "\n",
    "        Parameter\n",
    "        ----------\n",
    "            X : 输入张量, 形状应为(batch_size, channels, *signal_shape), signal_shape的长度应与signal_dim一致\n",
    "        \n",
    "        Return\n",
    "        ----------\n",
    "            傅里叶系数的前半部分, 形状根据输入信号维度不同而不同\n",
    "        \"\"\"\n",
    "        # 检查输入维度是否匹配\n",
    "        if len(X.shape)-2 != self.signal_dim:\n",
    "            raise ValueError(f\"输入张量维度应为 (batch, channels, {self.signal_dim}信号)\")\n",
    "\n",
    "        # 根据信号维度选择傅里叶变换函数\n",
    "        if self.signal_dim == 1:\n",
    "            # 1D信号: (batch, channels, length)\n",
    "            fft_result = torch.fft.rfft(X, dim=-1)\n",
    "        elif self.signal_dim == 2:\n",
    "            # 2D信号: (batch, channels, height, width)\n",
    "            fft_result = torch.fft.rff2(X, dim=(-2, -1))\n",
    "        elif self.signal_dim == 3:\n",
    "            # 3D信号: (batch, channels, depth, height, width)\n",
    "            fft_result = torch.fft.rfftn(X, dim=(-3, -2, -1))\n",
    "        else:\n",
    "            raise ValueError(\"signal_dim必须为1、2或3\")\n",
    "        \n",
    "        return fft_result # 返回傅里叶系数的前半部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceb80689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.8320+0.0000j,  0.9570+0.3435j,  0.9783+0.0000j],\n",
       "         [ 2.9490+0.0000j,  0.2558-0.8542j,  1.8705+0.0000j],\n",
       "         [-1.4231+0.0000j,  0.5572-0.1542j,  1.1135+0.0000j]],\n",
       "\n",
       "        [[ 1.7841+0.0000j,  0.4297+0.4376j,  0.5546+0.0000j],\n",
       "         [-1.4070+0.0000j,  1.7606+0.2316j, -2.7826+0.0000j],\n",
       "         [ 0.7130+0.0000j,  1.1661-0.9240j, -2.1249+0.0000j]],\n",
       "\n",
       "        [[-3.1791+0.0000j, -0.4591-0.4848j, -0.2474+0.0000j],\n",
       "         [-0.2449+0.0000j, -0.0964-0.1509j, -3.1830+0.0000j],\n",
       "         [ 0.5365+0.0000j, -0.9598+0.8740j, -0.3699+0.0000j]],\n",
       "\n",
       "        [[ 3.6898+0.0000j, -0.2435+1.8472j,  5.7723+0.0000j],\n",
       "         [ 2.2252+0.0000j, -1.4074+0.6666j, -1.0055+0.0000j],\n",
       "         [-1.8485+0.0000j, -0.1693+1.3783j,  0.5546+0.0000j]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1d = FourierCoefficientLayer(1)\n",
    "x_1d(torch.randn(4, 3, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
